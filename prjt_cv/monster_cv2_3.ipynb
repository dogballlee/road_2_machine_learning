{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 背景建模"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 帧差法\n",
    "由于场景中的目标在运动，目标的影响在不同的图像帧中的位置不同。该类算法对时间上连续的两帧图像进行查分运算，不同帧对应的像素点相减，判断灰度差的绝对值，当绝对值超过一定的阈值时，即可判断为运动的目标，从而实现目标的检测功能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 混合高斯模型\n",
    "在测试阶段，对新来的像素点值与混合高斯模型中的每一个均值进行比较，如果其差值在2倍的方差之间的话，则认为是背景，否则认为是前景。将前景赋值为255，背景赋值为0，这样就形成了一幅前景二值图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 混合高斯模型学习方法\n",
    "1、首先初始化每个高斯模型矩阵参数\n",
    "2、取视频中T帧数据图像用来训练高斯混合模型，来了第一个像素之后用它来当做第一高斯分布\n",
    "3、当后帧的像素值传来时，与前面已有的高斯的均值比较，如果该像素点的值与其模型均值差在3倍的方差内，则属于该分部，并对其进行参数更新\n",
    "4、如果下一次来的像素不满足当前的高斯分布，用它来创建一个新的高斯分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "test_path = r'D:\\\\py_project\\\\test.avi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#测试视频\n",
    "cap = cv2.VideoCapture(test_path)\n",
    "#形态学操作需要使用\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))\n",
    "#创建混合高斯模型用于背景建模\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    fgmask = fgbg.apply(frame)\n",
    "    #形态学开运算去噪点\n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "    #寻找视频中的轮廓\n",
    "    im, contours, hierarchy = cv2.findContours(fgmask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for c in contours:\n",
    "        #计算各轮廓的周长\n",
    "        perimeter = cv2.arcLength(c,True)\n",
    "        if perimeter > 188:\n",
    "            #找到一个直矩形（不会旋转）\n",
    "            x,y,w,h = cv2.boundingRect(c)\n",
    "            #画出矩形\n",
    "            cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)  \n",
    "\n",
    "    cv2.imshow('frame', frame)\n",
    "    cv2.imshow('fgmask', fgmask)\n",
    "    k = cv2.waitKey(150) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "            \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 光流估计\n",
    "光流估计是空间运动物体在观测成像平面上的像素运动的瞬时速度，根据各个像素点的速度矢量特征，可以对图像进行动态分析，例如目标跟踪\n",
    "\n",
    "*亮度恒定：同一点随着时间的变化，其亮度不会发生改变  \n",
    "\n",
    "*小运动：随着时间的变化不会引起位置的剧烈变化，只有小运动的情况下才能用前后帧之间单位位置变化引起的灰度变化去近似灰度对位置的偏导数  \n",
    "\n",
    "*空间一致：一个场景上临近的点投影到图像上也是离近点，且临近点速度一致。因为光流法基本方程约束只有一个，而要求x,y方向的速度，有两个位置变量。所以需要连立多个方程求解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(test_path)\n",
    "\n",
    "#角点检测所需参数\n",
    "feature_params = dict(maxCorners = 100,qualityLevel = 0.3,minDistance = 7)\n",
    "\n",
    "#lucas_kanade参数\n",
    "lk_params = dict(winSize = (15,15),maxLevel = 2)\n",
    "\n",
    "#随机颜色线条\n",
    "color = np.random.randint(0,255,(100,3))\n",
    "\n",
    "#拿到第一帧图像\n",
    "ret, old_frame = cap.read()\n",
    "old_gray = cv2.cvtColor(old_frame,cv2.COLOR_BGR2GRAY)\n",
    "#返回所有检测特征点，需要输入图像，角点最大数量（效率），品质因子（特征值越大越好，来筛选）\n",
    "#距离相当于这区间有比这个角点强的，就不要这个角点了\n",
    "p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
    "\n",
    "#创建一个mask\n",
    "mask = np.zeros_like(old_frame)\n",
    "\n",
    "while(True):\n",
    "    ret,frame = cap.read()\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #需要传入前一帧和当前图像以及前一帧检测到的角点\n",
    "    pl,st,err = cv2.calcOpticalFlowPyrLK(old_gray,frame_gray,p0,None, **lk_params)\n",
    "    \n",
    "    #st=1表示\n",
    "    good_new = pl[st==1]\n",
    "    good_old = p0[st==1]\n",
    "    \n",
    "    #绘制轨迹\n",
    "    for i,(new,old) in enumerate(zip(good_new,good_old)):\n",
    "        a,b = new.ravel()\n",
    "        c,d = old.ravel()\n",
    "        mask = cv2.line(mask,(a,b),(c,d),color[i].tolist(),2)\n",
    "        frame = cv2.circle(frame,(a,b),5,color[i].tolist(),-1)\n",
    "    img = cv2.add(frame,mask)\n",
    "    \n",
    "    cv2.imshow('frame',img)\n",
    "    k = cv2.waitKey(150) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "    \n",
    "    #更新\n",
    "    old_gray = frame_gray.copy()\n",
    "    p0 = good_new.reshape(-1,1,2)\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
